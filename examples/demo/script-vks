#!/bin/bash

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
HOME_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )"/../.. && pwd )"
CYMBA_DIR=${HOME_DIR}/../cymba
FLOTTA_AGENT_DIR=${HOME_DIR}/../flotta-device-worker

source ${SCRIPT_DIR}/config
source ${SCRIPT_DIR}/demo-magic

TYPE_SPEED=30
TYPE_SPEED_BK=$TYPE_SPEED
#PROMPT_AFTER=1
DEMO_PROMPT="☸️ vkshost> "

function pause() {
  if [[ -n "${NO_WAIT}" ]]; then
    sleep 2
  else
    if [[ -n "${1-}" ]]; then
      sleep "$1"
    else
      wait
    fi
  fi
}

END=false
function end() {
  END=true
}
trap end SIGINT

kubectl config use-context ${VKS_HOST_CTX}
cd $HOME_DIR
export PATH=$PATH:$(pwd)/deploy

if [ "$START_CLEAN" == "true" ]; then
  echo "start clean !"
  kubectl vh delete vks1 2> /dev/null
  kubectl vh delete vks2 2> /dev/null
  kubectl vh delete vks3 2> /dev/null
  kubectl vh delete-kubeconfig vks1
  kubectl vh delete-kubeconfig vks2
  kubectl vh delete-kubeconfig vks3
fi

if [ "$DELETE_PODMAN_AGENTS" == "true" ]; then
  echo "delete podman agents !"
  export SSH_CMD=${SSH_PODMAN1}
  ${CYMBA_DIR}/deploy/delete-agent.sh 2>/dev/null
  export SSH_CMD=${SSH_PODMAN2}
  ${CYMBA_DIR}/deploy/delete-agent.sh 2>/dev/null
  ${FLOTTA_AGENT_DIR}/deploy/delete-agent.sh 2>/dev/null
  ${SSH_PODMAN1} podman pod rm --all -f
  ${SSH_PODMAN2} podman pod rm --all -f
fi  

clear

##################### Demo starts here #########################

VKS=vks1
pe "kubectl config current-context"
pe "kubectl get nodes"
pe "kubectl vh create ${VKS}"
pod=$(kubectl get pods -l job-name=${VKS}-job --no-headers -o custom-columns=":metadata.name")
pe "kubectl logs $pod -f"
pe "kubectl get pods -n ${VKS}-system"
REG_OPTS=$(kubectl get cm -n ${VKS}-system join-command -o jsonpath='{.data.join-cmd}' | sed -e "s/^\w*\ *//; 1{s/[^ ]\+\s*$//}")

pe "kubectl vh merge-kubeconfig ${VKS}"
pe "kubectl config use-context ${VKS}"
DEMO_PROMPT="☸️  ${VKS}> "
pe "kubectl get nodes"
pe "kubectl get pods --all-namespaces"
pe "kubectl get managedclusters"

# register cluster1
CLUSTER=cluster1
pe "${SSH_CLUSTERS} kubectl config use-context kind-$CLUSTER"
TYPE_SPEED=10000
pe "${SSH_CLUSTERS} clusteradm ${REG_OPTS} $CLUSTER"
TYPE_SPEED=$TYPE_SPEED_BK
pause

pe "kubectl get csr"
pe "clusteradm accept --clusters $CLUSTER"
pe "kubectl get managedclusters"

# register cluster2
CLUSTER=cluster2
pe "${SSH_CLUSTERS} kubectl config use-context kind-$CLUSTER"
TYPE_SPEED=10000
pe "${SSH_CLUSTERS} clusteradm ${REG_OPTS} $CLUSTER"
TYPE_SPEED=$TYPE_SPEED_BK
pause

pe "kubectl get csr"
pe "clusteradm accept --clusters $CLUSTER"
pe "kubectl get managedclusters"

# register podman1
PODMAN=podman1
export SSH_CMD=${SSH_PODMAN1}
TYPE_SPEED=10000
pe "${CYMBA_DIR}/deploy/deploy-agent.sh ${REG_OPTS} ${PODMAN}"
TYPE_SPEED=$TYPE_SPEED_BK
pe "kubectl get csr"
pe "clusteradm accept --clusters $PODMAN"
pe "kubectl get managedclusters"

#register podman2
PODMAN=podman2
export SSH_CMD=${SSH_PODMAN2}
TYPE_SPEED=10000
# TODO - build cm in vh and read it to create reg command
pe " ${FLOTTA_AGENT_DIR}/deploy/deploy-agent.sh join --hub-apiserver 18.221.76.241:31435"
TYPE_SPEED=$TYPE_SPEED_BK
pe "kubectl get edgedevices"

# create clustersets
pe "kubectl apply -f examples/clusterset1.yaml"
pe "kubectl apply -f examples/clusterset2.yaml"

# create clustersets bindings
pe "kubectl apply -f examples/clusterset1-binding.yaml"
pe "kubectl apply -f examples/clusterset2-binding.yaml"

# label all clusters
CLUSTER=cluster1
TYPE_SPEED=1000
pe "kubectl label managedcluster $CLUSTER cluster.open-cluster-management.io/clusterset=clusterset1"
pe "kubectl label managedcluster $CLUSTER location=edge1"

CLUSTER=cluster2
pe "kubectl label managedcluster $CLUSTER cluster.open-cluster-management.io/clusterset=clusterset1"
pe "kubectl label managedcluster $CLUSTER location=edge1"

PODMAN=podman1
pe "kubectl label managedcluster $PODMAN cluster.open-cluster-management.io/clusterset=clusterset2"
pe "kubectl label managedcluster $PODMAN location=edge2"

PODMAN=podman2
EDGE_DEV_NAME=$(kubectl get edgedevices -o jsonpath='{.items[0].metadata.name}')
pe "kubectl label edgedevice $EDGE_DEV_NAME location=edge2"

# show & apply policy
pe "vim examples/placement1.yaml"
pe "kubectl apply -f examples/placement1.yaml"

pe "vim examples/placement2.yaml"
pe "kubectl apply -f examples/placement2.yaml"

# create appbundle1
pe "vim examples/appbundle1.yaml"
pe "kubectl apply -f examples/appbundle1.yaml"
pe "kubectl get manifestworks --all-namespaces"

# create appbundle2 & deployment
pe "vim examples/appbundle2-empty.yaml"
pe "kubectl apply -f examples/appbundle2-empty.yaml"
pe "vim examples/deployment1.yaml"
pe "kubectl apply -f examples/deployment1.yaml"
pause
pe "kubectl get appbundle appbundle2 -o yaml"

# create appbundle3
pe "vim examples/appbundle3.yaml"
pe "kubectl apply -f examples/appbundle3.yaml"
pe "kubectl get manifestworks --all-namespaces"

# create edgedeployment
pe "vim examples/edgedeployment1.yaml"
pe "kubectl apply -f examples/edgedeployment1.yaml"

# show can create more virtual hubs

VKS=vks2
pe "kubectl config use-context ${VKS_HOST_CTX}"
pe "kubectl vh create ${VKS}"
pod=$(kubectl get pods -l job-name=${VKS}-job --no-headers -o custom-columns=":metadata.name")
pe "kubectl logs $pod -f"
pe "kubectl get pods -n ${VKS}-system"
pe "kubectl vh merge-kubeconfig ${VKS}"
pe "kubectl config use-context ${VKS}"
DEMO_PROMPT="☸️  ${VKS}> "
pe "kubectl get managedclusters"


while [ "$END" == "false" ]
do
  cmd
done

wait
